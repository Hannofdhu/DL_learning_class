{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca870ae7",
   "metadata": {},
   "source": [
    "实例化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0c016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad5981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'使用{device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf67c23",
   "metadata": {},
   "source": [
    "所有Neural Network都继承自nn.Module这一复类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe294244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        #继承nn.Module,改写__init__方法\n",
    "        #实例化nn.Flatten\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            #输入维度输出维度\n",
    "            nn.Linear(28*28,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10))\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55a4b8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n若实现tf.summary（）方法，\\n可以使用GitHub中的pytorch-summary库\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实例化，并将类的附属量都放入设备运行\n",
    "model = NeuralNetwork().to(device) \n",
    "print(model)\n",
    "\"\"\"\n",
    "若实现tf.summary（）方法，\n",
    "可以使用GitHub中的pytorch-summary库\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9e11b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型结构 NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "层:linear_relu_stack.0.weight|size:torch.Size([512, 784])|值:tensor([[ 0.0295, -0.0292,  0.0292,  ..., -0.0009,  0.0240, -0.0127],\n",
      "        [-0.0236, -0.0064,  0.0195,  ...,  0.0140,  0.0169,  0.0018]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "\n",
      "层:linear_relu_stack.0.bias|size:torch.Size([512])|值:tensor([ 0.0187, -0.0311], grad_fn=<SliceBackward0>)\n",
      "\n",
      "层:linear_relu_stack.2.weight|size:torch.Size([512, 512])|值:tensor([[-0.0153, -0.0206, -0.0367,  ..., -0.0223, -0.0348,  0.0433],\n",
      "        [ 0.0019, -0.0013, -0.0311,  ..., -0.0055,  0.0419,  0.0097]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "\n",
      "层:linear_relu_stack.2.bias|size:torch.Size([512])|值:tensor([0.0277, 0.0279], grad_fn=<SliceBackward0>)\n",
      "\n",
      "层:linear_relu_stack.4.weight|size:torch.Size([10, 512])|值:tensor([[ 0.0010, -0.0353, -0.0134,  ..., -0.0104,  0.0098,  0.0135],\n",
      "        [-0.0374,  0.0251, -0.0179,  ..., -0.0354,  0.0324,  0.0410]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "\n",
      "层:linear_relu_stack.4.bias|size:torch.Size([10])|值:tensor([-0.0215, -0.0331], grad_fn=<SliceBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#查看模型结构\n",
    "print('模型结构',model,'\\n\\n')\n",
    "\n",
    "for name,param in model.named_parameters():\n",
    "    print(f'层:{name}|size:{param.size()}|值:{param[:2]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a45f3b",
   "metadata": {},
   "source": [
    "使用model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3ce2998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0998, 0.1118, 0.1043, 0.1061, 0.0983, 0.0940, 0.0868, 0.1035, 0.0976,\n",
      "         0.0978]], grad_fn=<SoftmaxBackward0>)\n",
      "预测的类tensor([1])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((1,28,28),device=device)\n",
    "logits = model(X)\n",
    "pred_prabab = nn.Softmax(dim=1)(logits)\n",
    "print(pred_prabab)\n",
    "y_pred = pred_prabab.argmax(1)#返回数组中最大值元素的索引位置\n",
    "print(f'预测的类{y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "528b394b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 25])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten默认从第一个维度开始,即只剩下batch_size和所有其他维度\n",
    "#nn.Flatten(start_dim: int = 1, end_dim: int = -1)\n",
    "inp = torch.rand((32,1,5,5))\n",
    "flatten = torch.nn.Flatten()\n",
    "flatten(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9b12fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntorch.nn.Linear(\\n    in_features: int,\\n    out_features: int,\\n    bias: bool = True,\\n    device=None,\\n    dtype=None,\\n) -> None\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.nn.Linear(in)\n",
    "\"\"\"\n",
    "torch.nn.Linear(\n",
    "    in_features: int,\n",
    "    out_features: int,\n",
    "    bias: bool = True,\n",
    "    device=None,\n",
    "    dtype=None,\n",
    ") -> None\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3754ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.Sequential\n",
    "#         model = nn.Sequential(\n",
    "#                   nn.Conv2d(1,20,5),\n",
    "#                   nn.ReLU(),\n",
    "#                   nn.Conv2d(20,64,5),\n",
    "#                   nn.ReLU()\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb8b3907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#直接调用Sequential,batch_size=3\n",
    "flatten = nn.Flatten()\n",
    "layer1  = nn.Linear(28*28,20)\n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10)\n",
    ")\n",
    "input_image = torch.rand((3,28,28))\n",
    "logits = seq_modules(input_image)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_prabab = softmax(logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
