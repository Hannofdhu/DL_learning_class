{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c8888d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#类的形式\n",
    "from torch.nn import Dropout\n",
    "#函数的形式（上面那个类的forward函数最后调用的就是这个函数）\n",
    "from torch.nn.functional import dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd6cb5f",
   "metadata": {},
   "source": [
    "一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afcac8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6751, -0.0000, -0.5800, -0.0532, -0.0000, -0.0000, -0.6129,  0.0000,\n",
      "         -0.0000, -1.1305,  0.4967,  0.0000, -0.3838, -2.1778,  1.9867,  0.4818],\n",
      "        [ 1.8430,  1.1042,  0.8175,  0.4380, -0.5242, -1.4082, -0.3643, -0.0000,\n",
      "          0.0115, -1.3216,  0.9493, -1.0470,  1.7431,  0.1870,  0.7346,  0.0125],\n",
      "        [-0.5453,  0.0000, -1.1688, -1.6085,  0.9662,  0.7993, -1.3350,  1.2340,\n",
      "          0.0000, -0.0097,  0.9929, -0.3341,  0.0000, -0.7982, -1.9471, -0.8576],\n",
      "        [-1.1513, -0.0000,  1.5308, -0.0216, -1.4536,  0.0000, -0.2603,  0.0000,\n",
      "         -0.5696, -3.3678,  1.9186, -0.0094, -1.4286,  1.4907,  1.3030, -0.0000],\n",
      "        [ 0.7481, -0.2911, -0.9908, -0.1804, -0.7219, -0.4816,  0.0000, -1.5356,\n",
      "         -0.0000,  1.0395, -0.0000, -0.2099,  0.0000,  1.5210, -0.0000, -0.7926],\n",
      "        [-1.6812,  0.2775,  0.8190, -0.0000,  0.5364,  0.0790, -0.0268, -1.3946,\n",
      "          0.1641,  0.0000, -0.0000,  0.0000,  1.2746, -0.4535,  0.4387,  0.7070],\n",
      "        [-0.1090, -0.0841, -1.6279, -0.0000, -0.0000, -0.2551, -0.5013,  0.9365,\n",
      "          1.4197,  0.0000, -0.5099, -1.1777,  0.7577, -1.7404, -1.1143, -0.1429],\n",
      "        [-1.1100,  0.2624,  0.3691,  0.5762,  0.0000, -0.6009, -0.0000, -0.0000,\n",
      "         -2.3230,  0.3305, -0.4759, -1.3358, -0.0919, -0.0000,  1.5697, -0.0000],\n",
      "        [ 0.0000, -1.1537, -0.0000,  0.3560, -1.4280,  0.0000, -0.0000, -0.8245,\n",
      "          1.7497,  1.3200, -0.5885,  1.2913,  0.0000,  1.0563,  0.0000, -0.7643],\n",
      "        [-1.2152,  1.5918,  0.9020,  0.0000, -0.0000, -0.3825, -0.0527,  0.4667,\n",
      "          0.6678,  0.2932,  0.3509,  0.3089, -1.0838, -0.0000,  0.3274,  1.1226],\n",
      "        [-0.6403, -0.1399,  0.0000,  1.2191,  0.1714, -1.1818,  0.2634, -0.2094,\n",
      "         -0.6799,  1.0038, -0.8916,  0.3973, -0.4254,  0.0000, -0.0000,  0.5692],\n",
      "        [-1.3954,  0.4212,  0.0161, -0.0627, -0.2889,  0.6969, -0.8480, -0.0303,\n",
      "          3.5442,  0.4345,  0.2201,  0.1531, -0.1690,  0.7767,  0.0254,  0.3736],\n",
      "        [ 0.1432, -0.2164, -0.0000,  0.1690, -1.4863,  0.9876,  0.0000,  0.6175,\n",
      "          1.0641, -0.7029,  0.0000,  1.3467, -0.0000, -1.2725,  1.4466,  0.0000],\n",
      "        [ 0.0000, -1.1181,  0.0000,  0.4018, -0.7579, -0.4346, -0.0000,  0.9425,\n",
      "         -2.3262, -1.2790,  2.3509,  1.3121,  2.1996, -0.5827,  0.0000, -0.2910],\n",
      "        [-0.5181, -0.6070,  1.3959, -1.4519, -0.9735, -1.7774, -1.4670,  0.0044,\n",
      "          0.0000, -2.3835,  0.5932,  2.7867,  0.0000,  2.1929,  0.3278, -1.9697],\n",
      "        [ 0.3397, -1.4202,  0.1192, -0.0435,  0.0000,  0.3079,  1.2715,  0.0227,\n",
      "         -0.8918, -1.5904, -0.6871, -1.7369,  0.0000,  1.3282, -0.0000,  0.6616],\n",
      "        [ 0.6227,  1.6070, -2.1910,  1.7206,  0.9035,  0.7091, -0.1223, -0.9427,\n",
      "          0.0000, -0.0000, -1.3930, -0.0000,  0.6009, -2.2205, -0.0000, -0.5914],\n",
      "        [ 0.6979, -0.0000, -1.8428,  0.6108, -0.0275, -1.9060,  0.6893,  0.7290,\n",
      "         -0.0038, -0.3114,  0.8234,  1.5745,  0.3701, -2.6035, -1.0818, -2.4689],\n",
      "        [ 1.0856, -0.5800, -1.8964,  0.8338, -1.0576, -1.8629, -2.6013,  0.0000,\n",
      "          0.3632, -0.5760,  1.5109,  1.3610, -0.0000, -0.4992,  3.1502,  2.6128],\n",
      "        [-0.0000, -0.8925, -0.5754, -1.2496,  0.5013,  0.1712, -0.0000, -1.9548,\n",
      "          0.4679,  0.0000, -0.0000, -0.5759, -0.0000,  0.2952, -0.0000, -0.0000]])\n"
     ]
    }
   ],
   "source": [
    "m = Dropout(p=0.2)\n",
    "b = torch.randn(20,16)\n",
    "output = m(b)\n",
    "output.shape\n",
    "print(output)#约20%的节点被置为零"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfaf5b2",
   "metadata": {},
   "source": [
    "二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fdad7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16])\n",
      "tensor([[ 1.6751, -0.0000, -0.5800, -0.0532, -0.8176, -0.2532, -0.0000,  0.5470,\n",
      "         -0.8931, -0.0000,  0.4967,  0.3242, -0.3838, -0.0000,  1.9867,  0.4818],\n",
      "        [ 1.8430,  1.1042,  0.8175,  0.4380, -0.5242, -0.0000, -0.3643, -0.5785,\n",
      "          0.0115, -1.3216,  0.9493, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.5453,  0.8035, -1.1688, -1.6085,  0.9662,  0.7993, -1.3350,  1.2340,\n",
      "          0.0000, -0.0097,  0.9929, -0.3341,  0.0000, -0.7982, -1.9471, -0.8576],\n",
      "        [-1.1513, -0.2681,  1.5308, -0.0216, -1.4536,  0.4179, -0.2603,  0.1257,\n",
      "         -0.5696, -3.3678,  1.9186, -0.0000, -1.4286,  1.4907,  1.3030, -0.3067],\n",
      "        [ 0.7481, -0.2911, -0.9908, -0.1804, -0.7219, -0.4816,  0.0000, -1.5356,\n",
      "         -0.0000,  1.0395, -0.1227, -0.0000,  0.0000,  1.5210, -1.3142, -0.7926],\n",
      "        [-1.6812,  0.2775,  0.8190, -0.6373,  0.5364,  0.0790, -0.0268, -0.0000,\n",
      "          0.1641,  0.7709, -1.1400,  0.9763,  1.2746, -0.0000,  0.4387,  0.7070],\n",
      "        [-0.1090, -0.0841, -0.0000, -0.5533, -1.0694, -0.2551, -0.5013,  0.9365,\n",
      "          1.4197,  0.5879, -0.5099, -1.1777,  0.7577, -1.7404, -1.1143, -0.1429],\n",
      "        [-1.1100,  0.2624,  0.0000,  0.0000,  0.0000, -0.6009, -1.4080, -0.6602,\n",
      "         -2.3230,  0.0000, -0.4759, -1.3358, -0.0919, -0.0000,  1.5697, -1.8560],\n",
      "        [ 0.0000, -1.1537, -0.6346,  0.3560, -1.4280,  0.0000, -0.0000, -0.8245,\n",
      "          1.7497,  1.3200, -0.5885,  1.2913,  0.0000,  1.0563,  0.0159, -0.7643],\n",
      "        [-1.2152,  1.5918,  0.9020,  0.0000, -0.0377, -0.0000, -0.0527,  0.0000,\n",
      "          0.6678,  0.2932,  0.3509,  0.3089, -1.0838, -0.7284,  0.0000,  1.1226],\n",
      "        [-0.6403, -0.1399,  0.2829,  1.2191,  0.1714, -0.0000,  0.2634, -0.2094,\n",
      "         -0.6799,  0.0000, -0.8916,  0.0000, -0.4254,  3.0680, -1.9285,  0.5692],\n",
      "        [-1.3954,  0.0000,  0.0161, -0.0627, -0.2889,  0.6969, -0.8480, -0.0303,\n",
      "          3.5442,  0.0000,  0.0000,  0.0000, -0.1690,  0.7767,  0.0254,  0.0000],\n",
      "        [ 0.1432, -0.2164, -1.5695,  0.1690, -0.0000,  0.0000,  2.9856,  0.6175,\n",
      "          1.0641, -0.7029,  1.6588,  1.3467, -1.9011, -0.0000,  1.4466,  0.6983],\n",
      "        [ 1.3158, -1.1181,  0.0000,  0.4018, -0.0000, -0.0000, -1.6612,  0.9425,\n",
      "         -2.3262, -1.2790,  2.3509,  0.0000,  2.1996, -0.5827,  1.2355, -0.2910],\n",
      "        [-0.5181, -0.6070,  0.0000, -0.0000, -0.9735, -0.0000, -1.4670,  0.0044,\n",
      "          0.5399, -2.3835,  0.0000,  0.0000,  0.1748,  2.1929,  0.3278, -1.9697],\n",
      "        [ 0.3397, -1.4202,  0.0000, -0.0000,  0.0000,  0.3079,  1.2715,  0.0000,\n",
      "         -0.8918, -1.5904, -0.0000, -1.7369,  1.1881,  0.0000, -0.0887,  0.6616],\n",
      "        [ 0.6227,  1.6070, -2.1910,  1.7206,  0.9035,  0.7091, -0.1223, -0.9427,\n",
      "          0.0000, -0.0000, -1.3930, -1.4894,  0.6009, -2.2205, -0.2078, -0.5914],\n",
      "        [ 0.0000, -0.0872, -1.8428,  0.6108, -0.0275, -1.9060,  0.0000,  0.0000,\n",
      "         -0.0000, -0.3114,  0.8234,  1.5745,  0.0000, -2.6035, -0.0000, -2.4689],\n",
      "        [ 1.0856, -0.5800, -1.8964,  0.8338, -1.0576, -0.0000, -2.6013,  1.6740,\n",
      "          0.3632, -0.5760,  1.5109,  1.3610, -0.7664, -0.0000,  3.1502,  2.6128],\n",
      "        [-0.8534, -0.8925, -0.5754, -1.2496,  0.0000,  0.1712, -0.0000, -1.9548,\n",
      "          0.4679,  0.2674, -0.1731, -0.5759, -0.3344,  0.2952, -0.0000, -0.0181]])\n"
     ]
    }
   ],
   "source": [
    "output = dropout(b,p=0.2,training=True,inplace=False)#手动设置training\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45436dcb",
   "metadata": {},
   "source": [
    "# 使用numpy完成dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c493f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#方法一\n",
    "def train(rate,x,w1,b1,w2,b2):\n",
    "    layer1 = np.maximum(0,np.dot(w1,x)+b1)\n",
    "    #在二项分布中采集样本\n",
    "    mask1 = np.random.binomial(1,1-rate,layer1.shape)\n",
    "    layer1 = layer1*mask1\n",
    "    \n",
    "    layer2 = np.maximum(0,np.dot(w2,layer1)+b2)\n",
    "    mask2 = np.random.binomial(1,1-rate,layer2.shape)\n",
    "    layer2 = layer2*mask2\n",
    "    \n",
    "    return layer2\n",
    "\n",
    "def test(rate,x,w1,b1,w2,b2):\n",
    "    layer1 = np.maximum(0,np.dot(w1,x)+b1)\n",
    "    layer1 = layer1*(1-rate)\n",
    "    \n",
    "    layer2 = np.maximum(0,np.dot(w2,layer1)+b2)\n",
    "    layer2 = layer2*(1-rate)\n",
    "    \n",
    "    return layer2\n",
    "\n",
    "#方法二\n",
    "def another_train(rate,x,w1,b1,w2,b2):\n",
    "    layer1 = np.maximum(0,np.dot(w1,x)+b1)\n",
    "    #在二项分布中采集样本\n",
    "    mask1 = np.random.binomial(1,1-rate,layer1.shape)\n",
    "    layer1 = layer1*mask1\n",
    "    layer1 = layer1/(1-rate)\n",
    "    \n",
    "    layer2 = np.maximum(0,np.dot(w2,layer1)+b2)\n",
    "    mask2 = np.random.binomial(1,1-rate,layer2.shape)\n",
    "    layer2 = layer2*mask2\n",
    "    layer2 = layer2/(1-rate)\n",
    "    \n",
    "    return layer2\n",
    "\n",
    "#这样就没有scale的步骤了，减少了测试计算量\n",
    "def another_test(x,w1,b1,w2,b2):\n",
    "    layer1 = np.maximum(0,np.dot(w1,x)+b1)\n",
    "    layer2 = np.maximum(0,np.dot(w2,layer1)+b2)\n",
    "    \n",
    "    return layer2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
